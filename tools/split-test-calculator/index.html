<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><title>Bayesian A/B Test Calculator</title><link rel="stylesheet" href="style.css"></head><body><div class="wrapper header"><h1 class="logo">Bayesian A/B Test Calculator</h1><p class="tagline">The Beta-Bernoulli model in the context of A/B testing.</p></div><div class="wrapper"><div class="sidebar note-wrapper"><h3>Need Help?</h3><p class="note">See <a href="#explanation">here</a> or read more about Bayesian inference in A/B testing on
<a href="http://developers.lyst.com/2014/05/10/bayesian-ab-testing">Lyst's blog</a>.
</p></div><div class="content"><h3 class="instructions-title">TL:DR; Instructions</h3><ol><li><span class="number">1</span>Specify the prior alpha and beta parameters.</li><li><span class="number">2</span>Plot the priors and revise parameters as necessary.</li><li><span class="number">3</span>Enter data on the number of successes and failures in the test and control groups.</li><li><span class="number">4</span>Plot to see posterior distributions.</li></ol></div></div><div class="wrapper"><div class="sidebar"><form id="form"><h3 class="form-title">Your Data</h3><div class="form-group"><h4 class="form-group-title">Prior Parameters</h4><fieldset><label for="priorAlpha">Alpha</label><input id="priorAlpha" value="10" type="number" step="0.1" min="0.1" placeholder="&gt;= 0"></fieldset><fieldset><label for="priorBeta">Beta</label><input id="priorBeta" value="10" type="number" step="0.1" min="0.1" placeholder="&gt;= 0"></fieldset></div><div class="form-group"><h4 class="form-group-title control">Control Results</h4><fieldset><label for="controlSuccesses">Successes</label><input id="controlSuccesses" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset><fieldset><label for="controlFailures">Failures</label><input id="controlFailures" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset></div><div class="form-group"><h4 class="form-group-title test">Test Results</h4><fieldset><label for="testSuccesses">Successes</label><input id="testSuccesses" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset><fieldset><label for="testFailures">Failures</label><input id="testFailures" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset></div><div class="form-buttons"><input type="submit" value="Calculate"><input type="reset" value="Reset"></div></form></div><div class="content"><div class="chart"><h2 class="chart-title">Test and Control Probability Density Functions</h2><p class="chart-description">The success probability distributions in test and control groups.</p><div id="pdfplot"></div></div><div class="chart"><h2 class="chart-title">Histogram of Test - Control Probability</h2><p class="chart-description">Distribution of differences in success probability between test and control groups.</p><div id="histogram"></div></div><div class="chart"><h2 class="chart-title">Quantiles of the differences distribution.</h2><p class="chart-description">Posterior probability that the difference lies below the value x.</p><table id="quantileTable"></table><p>The average difference between test and control is: <span id="differenceMean">0</span>.
The probability that test performs better: <span id="testSuccessProbability">0.5</span>.
</p></div><div class="charts-summary"></div></div></div><div class="wrapper"><div id="explanation" class="content full-width"><h2>Explanation</h2><div class="columns"><div class="column"><p>This simple calculator uses the Beta-Bernoulli model (a binary outcome model, where the prior for the
success probability is a Beta distribution) applied in the A/B testing context, where the goal of
inference is understanding the probability that the test group performs better than the control group.</p><p>Bayesian inference consists in first specifying a prior belief about what effects are likely, and then
updating the prior with incoming data.</p><p>For example, if our conversion rate is 5%, we may say that it's reasonably likely that a change we want to
test could improve that by 5 percentage points&mdash;but that it is most likely that the change will have
no effect, and that it is entirely unlikely that the conversion rate will shoot up to 30% (after all, we
are only making a small change).</p><p>As the data start coming in, we start updating our beliefs. If the incoming data points point to an
improvement in the conversion rate, we start moving our estimate of the effect from the prior upwards; the
more data we collect, the more confident we are in it and the further we can move away from our prior. The
end result is what is called the posterior&mdash;a probability distribution describing the likely effect
from our treatment.</p></div><div class="column"><ol><li><span class="number">1</span> Specify the prior through the alpha and beta parameters of the
<a href="http://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a>. The parameter values
govern two things: the prior success probability (our belief about the average conversion rate, for
example) as well as the variance of the prior distribution (small alpha and beta will lead to a prior
distribution where success probabilities can vary quite a lot around their mean; large values will lead
to a distribution with a small variance). For example, setting alpha to 10 and beta to 10 will give us a
prior distribution where the expected success probability is 0.5, but there is a fair amount of
uncertainty around that value. Setting them to 100 and 100 will give us the same expected probability of
0.5, but the variance around that value will be much smaller.</li><li><span class="number">2</span> Have a look at the histogram of success probability differences between
the test and control. It expresses prior beliefs about the likely difference of success probabilities
between the test and control groups. Because we specified a symmetric prior, the belief is centered
around a difference of zero (a priori, A/B tests are just as likely to do worse as they are to do better
than the control). If our priors have a low variance, the histogram will put put a low weight on large
differences (it is unlikely that a test will do much better or much worse than the control); if the
priors have a high variance, large differences will be much more likely.</li><li><span class="number">3</span> Gather data!</li><li><span class="number">4</span> Input the number of successes (conversions, clicks and so on) and failures
in both the test and control groups. This triggers updating the priors with the data.</li><li><span class="number">5</span> The prior plots shift to express posterior (prior updated with data)
distributions. The density plots will (may) diverge, showing the posterior distributions of the success
probability in test and control groups. Similarly, the difference histogram will shift. The part of the
distribution lying to the right of zero expresses the confidence that the test performs better; the part
to the left that it performs worse.
</li></ol></div></div></div></div><script type="text/javascript" src="bayes.min.js"></script></body></html>