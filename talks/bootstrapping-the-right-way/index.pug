doctype html
html(lang="en")
  head
    title Bootstrapping the right way

    meta(name="description",
         content="A brief overview of bootstrap sampling and ways to avoid common pitfalls when bootstrapping your data.")
    meta(name="author", content="Yanir Seroussi")
    meta(charset="utf-8")
    meta(name="viewport", content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no")
    meta(name="apple-mobile-web-app-capable", content="yes")
    meta(name="apple-mobile-web-app-status-bar-style", content="black-translucent")

    link(rel="stylesheet", href="css/reveal.css")
    link(rel="stylesheet", href="css/theme/night.css")
    link(rel="stylesheet", href="lib/css/zenburn.css")
    link(rel="stylesheet", href="custom.css")

    // Print and PDF exports
    script.
      var link = document.createElement('link');
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName('head')[0].appendChild(link);

    <!--[if lt IE 9]><script src="lib/js/html5shiv.js"></script><![endif]-->

  body
    .reveal: .slides
      section
        h1 Bootstrapping the right way
        h4 Yanir Seroussi
        h6.
          <a href="https://yanirseroussi.com" target="_blank">yanirseroussi.com</a>
          |
          <a href="https://twitter.com/yanirseroussi" target="_blank">@yanirseroussi</a>
          |
          <a href="https://linkedin.com/in/yanirseroussi" target="_blank">linkedin.com/in/yanirseroussi</a>

      section
        h2 Main takeaway

        img(src="img/dont-believe-everything-you-read-on-the-internet-lincoln.jpg")

        aside.notes: ul
          li Don't believe blog posts
          li Don't believe conference talks
          li Trust, but verify
          li When needed, go back to primary sources

      section
        h2 Running example: A/B testing

        .fragment
          p We want to...
          p.indent.no-margin.neg-margin-top ...compare conversion rates and revenue
          p.indent.no-margin ...estimate uncertainty of metrics

        .fragment
          p We don't want...
          p.indent.no-margin.neg-margin-top ...binary answers
          p.indent.no-margin ...too many modelling assumptions

        aside.notes: ul
          li Explain A/B testing where we care about both conversion rates and revenue
          li Uncertainty: We want a range for the effect size, not just a yes/no answer
          li Modelling assumptions: We need something that we can justify to ourselves and others
          li The rest of the talk basically follows this outline

      section
        section
          h2 We want to compare...
          h1 conversion rates

        section
          h2 Sample &ndash; show some data

          p Green button / red button?

        section
          h2 Reminder #1: The central dogma

          a(href="https://www.gs.washington.edu/academics/courses/akey/56008/lecture/lecture1.pdf")
            img(src="img/central-dogma-of-statistics.png")

          aside.notes: ul
            li We have a population
            li We take a smaller sample from that population with probability
            li We use statistical inference to say something about the population
            li We care about the variability of our estimate for that population

        section
          h2 Reminder #2: Experiments and other out-of-scope issues

          p Stuff from Hernan about when they do or do not work

        section
          h2 Back to our problem: Let's ask the internet...

          p Screenshot of the hacker guide

        section
          h2 Using a known distribution to get sample confidence intervals

          p Show resultant CIs from post

        section
          h2 But we care about the difference!

          p Show difference distribution from post
          p Note it came from bootstrapping

        section
          h2 What if we care about the ratio?

          p extend the example, find a case where the ratio isn't significant but the difference is

        section
          h2 Side notes on conversions

          ul
            li Closed formula solutions exist for difference and ratios
            li If you're happy to make assumptions, the Bayesian parametric calculator is the way to go
            li Things get hairy if you care about more than the mean (e.g., comparing variances)

      section
        section
          h2 Detour:
          h1 On bootstrapping and confidence intervals

        section
          h2 What do confidence intervals even mean?

          p Formal definition
          p Discuss common misconceptions
          p Mention frequentist/Bayesian divide?

        section
          h2 The basic bootstrap example

          p Show a code snippet for percentile method + small number of resamples
          p You see this everywhere
          p Why should this work? A quick explanation of the theory

        section
          h2 What's wrong with the example?

          p Small number of resamples (quote JVP, Erik -- too small!)
          p Percentile method
          p Quote Hesterberg

        section
          h2 Why accept anything as a given when we can simulate?

          p The main reason for the popularity of bootstrapping is that it's easy to generate simulations
          p It's just as easy to
          p Simulation as the way to test that bootstrapping gives you the correct CI
          p Not all CIs are created equal (show Hesterberg results? or my own plots)

        section
          h2 A word of caution: Blog posts and talks < peer reviewed papers

          p Pros of posts and talks: Easy to digest, straight to the point
          p Cons of posts and talks: Can mislead, usually not critiqued
          p Pros of papers: Peer review, higher bar for acceptance (for some)
          p Cons of papers: Can be hard to digest and mislead; peer review is only as good as the peers
          p Best approach: Cross-check multiple resources and test test test
          p Cite a few papers
          p Something about laziness -- myself included
          p Note the irony of me giving a talk on the topic?

      section
        section
          h2 Back on course...
          h1 Comparing revenue

        section
          h2 Data data data

          p Simulation study: mixture of products with prices that vary geographically and people can purchase multiple products from each distribution
          p In general: can we learn about CI accuracy with real data? (e.g., population is purchases from 2018 &ndash; take different samples and see how well the CI works)

        section
          h2 Messier than conversions

          p Bootstrap is better motivated
          p Show an example where we changed the price of a few products (or just one)

        section
          h2 Different methods, different CIs

          p Use ARCH to get estimates (even sample size &ndash; 100, 1000, 10000)
          p Get true CI

        section
          h2 What about revenue over time?

          p Bootstrap is IID! Add this if there's time

      section
        section
          h2 Conclusion

          ul
            li Bootstrapping is a powerful tool
            li Testing powerful tools is a good idea
            li Reliable resources can be hard to find, but they're out there
            li Deeper understanding can come from Bayesian approaches

      // Abstract: Bootstrap sampling is being touted as a simple technique that any hacker can easily employ to
      // quantify the uncertainty of statistical estimates. However, despite its apparent simplicity, there are many
      // ways to misuse bootstrapping and thereby draw wrong conclusions about your data and the world. This talk gives
      // a brief overview of bootstrap sampling and discusses ways to avoid common pitfalls when bootstrapping your data.
      //
      // Proposal outline:
      // - An overview of bootstrap sampling, including how and why it works
      // - When one should and shouldn't use bootstrapping, including warnings about general issues like not drawing enough resamples
      // - A brief overview of confidence intervals, including the general definition, common misconceptions, and how to use them correctly
      // - Common bootstrapping methods to obtain confidence intervals
      // - How to make a decision whether the obtained confidence intervals are trustworthy
      // - Issues with bootstrapped confidence intervals and how to avoid them

      // TODO: 30 minutes including introductions and questions -- aim for 25 minutes?
      // TODO: stuff from https://yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/

      section
        h1 Questions?

    script(src="lib/js/head.min.js")
    script(src="js/reveal.js")
    script.
      Reveal.initialize({
        controls: true,
        controlsTutorial: false,
        progress: true,
        history: true,
        center: true,
        transition: 'slide',
        dependencies: [
          {
            src: 'lib/js/classList.js',
            condition: function() { return !document.body.classList; }
          },
          {
            src: 'plugin/markdown/marked.js',
            condition: function() { return !!document.querySelector( '[data-markdown]' ); }
          },
          {
            src: 'plugin/markdown/markdown.js',
            condition: function() { return !!document.querySelector( '[data-markdown]' ); }
          },
          {
            src: 'plugin/highlight/highlight.js',
            async: true,
            callback: function() { hljs.initHighlightingOnLoad(); }
          },
          {
            src: 'plugin/zoom-js/zoom.js',
            async: true
          },
          {
            src: 'plugin/notes/notes.js',
            async: true
          }
        ]
      });
